<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<title>Audio zu Raster-Pixel - Echtzeit</title>
<style>
  body { margin: 0; background: black; overflow: hidden; }
  canvas { display: block; image-rendering: pixelated; }
</style>
</head>
<body>
<canvas id="canvas"></canvas>
<script>
(async function() {
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');

  // Niedrige Auflösung für Performance
  const width = 256;
  const height = 256;
  canvas.width = width;
  canvas.height = height;

  const imageData = ctx.createImageData(width, height);
  const data = imageData.data;

  // Mikrofon einrichten
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const source = audioCtx.createMediaStreamSource(stream);

  // ScriptProcessorNode zum Abgreifen von Rohsamples
  const bufferSize = 4096; // größere Puffer → weniger Aufrufe
  const processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);
  source.connect(processor);
  processor.connect(audioCtx.destination);

  // Frame-Sample-Puffer
  const frameSamples = width * height;
  let frameBuffer = new Float32Array(frameSamples);
  let frameIndex = 0;

  processor.onaudioprocess = (e) => {
    const input = e.inputBuffer.getChannelData(0);
    for (let i = 0; i < input.length; i++) {
      frameBuffer[frameIndex] = Math.abs(input[i]);
      frameIndex++;
      if (frameIndex >= frameSamples) {
        renderFrame(frameBuffer);
        frameIndex = 0; // neues Frame beginnen
      }
    }
  };

  function renderFrame(buffer) {
    for (let i = 0; i < buffer.length; i++) {
      const brightness = Math.min(255, Math.floor(buffer[i] * 255));
      const idx = i * 4;
      data[idx] = brightness;
      data[idx+1] = brightness;
      data[idx+2] = brightness;
      data[idx+3] = 255;
    }
    ctx.putImageData(imageData, 0, 0);
  }

})();
</script>
</body>
</html>
