<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<title>Live-Mikrofon-Rauschen</title>
<style>
  body { margin: 0; background: black; overflow: hidden; }
  canvas { display: block; image-rendering: pixelated; }
</style>
</head>
<body>
<canvas id="canvas"></canvas>
<script>
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Canvas-Größe (Pixelbild klein, wird gestreckt)
const imgWidth = 128;
const imgHeight = 128;
canvas.width = imgWidth;
canvas.height = imgHeight;

// Canvas später skalieren auf Bildschirmgröße
canvas.style.width = window.innerWidth + "px";
canvas.style.height = window.innerHeight + "px";

navigator.mediaDevices.getUserMedia({ audio: true })
.then(stream => {
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const source = audioCtx.createMediaStreamSource(stream);
  const analyser = audioCtx.createAnalyser();
  analyser.fftSize = 256; // kleine FFT = mehr Samples = mehr Pixel
  source.connect(analyser);

  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  function draw() {
    requestAnimationFrame(draw);

    // Mikrofon-TimeDomain (Rohsamples)
    analyser.getByteTimeDomainData(dataArray);

    // Pixelbild vorbereiten
    const imgData = ctx.createImageData(imgWidth, imgHeight);
    for (let i = 0; i < imgData.data.length / 4; i++) {
      const val = dataArray[i % bufferLength]; // 0..255
      imgData.data[i * 4 + 0] = val; // R
      imgData.data[i * 4 + 1] = val; // G
      imgData.data[i * 4 + 2] = val; // B
      imgData.data[i * 4 + 3] = 255; // Alpha
    }

    // Pixelbild anzeigen
    ctx.putImageData(imgData, 0, 0);
  }

  draw();
})
.catch(err => {
  console.error("Mikrofon Zugriff verweigert:", err);
});
</script>
</body>
</html>
