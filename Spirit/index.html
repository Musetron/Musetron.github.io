<!doctype html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Spirit-Viewer</title>
<style>
  html,body { height:100%; margin:0; background:#000; color:#fff; font-family: Arial, sans-serif; }
  canvas { display:block; background:#000; }
  #info { position:fixed; left:8px; top:8px; font-size:12px; opacity:0.9; }
  /* keine zusätzliche UI-Elemente sichtbar — alles wird in Canvas gezeichnet */
</style>
</head>
<body>
<canvas id="cv"></canvas>
<div id="info">Spirit-Viewer</div>

<script>
/* -----------------------
   Parameter (gleiche Namen)
   ----------------------- */
let WINDOW_WIDTH = 420, WINDOW_HEIGHT = 600;
const FPS = 60;
const WIDTH = 64, HEIGHT = 64; // TV-Auflösung
const SAMPLE_RATE_REQUEST = 44100; // Wunsch, tatsächl. kann audioCtx.sampleRate weichen
const SAMPLES_PER_FRAME = WIDTH * HEIGHT;
const FFT_SIZE = 512;
const SPEC_HISTORY = 256;

/* -----------------------
   Puffer (Ringbuffer)
   ----------------------- */
class RingFloat {
  constructor(maxlen){
    this.maxlen = maxlen;
    this.buf = new Float32Array(maxlen);
    this.start = 0;
    this.length = 0;
  }
  pushArray(arr){
    for(let i=0;i<arr.length;i++) this.push(arr[i]);
  }
  push(v){
    if(this.length < this.maxlen){
      this.buf[(this.start + this.length) % this.maxlen] = v;
      this.length++;
    } else {
      // overwrite oldest
      this.buf[this.start] = v;
      this.start = (this.start + 1) % this.maxlen;
    }
  }
  peekLast(n){
    // return last n samples as Float32Array (not removing)
    if(n > this.length) n = this.length;
    const out = new Float32Array(n);
    for(let i=0;i<n;i++){
      const idx = (this.start + this.length - n + i) % this.maxlen;
      out[i] = this.buf[idx];
    }
    return out;
  }
  popFirst(n){
    if(n > this.length) n = this.length;
    const out = new Float32Array(n);
    for(let i=0;i<n;i++){
      out[i] = this.buf[(this.start + i) % this.maxlen];
    }
    this.start = (this.start + n) % this.maxlen;
    this.length -= n;
    if(this.length < 0) this.length = 0;
    return out;
  }
  available(){ return this.length; }
}
let frame_buffer = new RingFloat(SAMPLES_PER_FRAME * 4);
let output_buffer = new RingFloat(SAMPLES_PER_FRAME * 4);
let spec_buffer = new Float32Array(SPEC_HISTORY * WIDTH); // row-major: row0..rowN-1 each width long

/* -----------------------
   Layout
   ----------------------- */
let canvas = document.getElementById('cv');
let ctx = canvas.getContext('2d');
let TV_HEIGHT, SPEC_TOP, SPEC_HEIGHT;
let slider_rect;
function update_layout(){
  TV_HEIGHT = Math.floor(WINDOW_HEIGHT * 2 / 3);
  SPEC_TOP = TV_HEIGHT + 20;
  SPEC_HEIGHT = WINDOW_HEIGHT - SPEC_TOP - 40;
  slider_rect = { x:50, y:WINDOW_HEIGHT - 30, width: WINDOW_WIDTH - 100, height:20 };
}
update_layout();

/* -----------------------
   Slider & Bandpass
   ----------------------- */
let slider_pos = slider_rect.x + Math.floor(slider_rect.width / 2);
let dragging_slider = false;
let brightness = 0.5;   // Lautstärke/Helligkeit (0..1)
let contrast = 0.5;     // Gain/Kontrast (0..1)

let line_left = Math.floor(WINDOW_WIDTH / 4);
let line_right = Math.floor(WINDOW_WIDTH * 3 / 4);
let line_middle = Math.floor((line_left + line_right) / 2);
let dragging_line = null;

/* -----------------------
   WebAudio Setup
   ----------------------- */
let audioCtx;
let micStream;
let sourceNode;
let analyser;
let filterNode; // bandpass approx
let gainNode;
let scriptNodeVis; // to capture samples for visualization (filtered)
let scriptNodeRaw; // optional
let actualSampleRate = SAMPLE_RATE_REQUEST;

async function startAudio(){
  try{
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({sampleRate: SAMPLE_RATE_REQUEST});
    actualSampleRate = audioCtx.sampleRate;
    // getUserMedia
    micStream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount:1, sampleRate: actualSampleRate }, video:false });
    sourceNode = audioCtx.createMediaStreamSource(micStream);

    analyser = audioCtx.createAnalyser();
    analyser.fftSize = FFT_SIZE;
    analyser.smoothingTimeConstant = 0.2;

    // Bandpass: we'll use a cascade to mimic adjustable bandpass width
    filterNode = audioCtx.createBiquadFilter();
    filterNode.type = 'bandpass';
    // We'll compute center frequency and Q dynamically from lines

    gainNode = audioCtx.createGain();
    gainNode.gain.value = 1.0;

    // ScriptProcessorNode (not ideal but simple) for visualization of filtered audio
    const bufferSize = 512; // matches FFT_SIZE
    scriptNodeVis = audioCtx.createScriptProcessor(bufferSize, 1, 1);
    scriptNodeVis.onaudioprocess = (e)=>{
      const input = e.inputBuffer.getChannelData(0);
      // apply brightness to captured visualization samples (like multiplying earlier)
      const scaled = new Float32Array(input.length);
      for(let i=0;i<input.length;i++){
        scaled[i] = input[i] * (brightness * 2);
      }
      frame_buffer.pushArray(scaled);
      // also push to output_buffer for safety (we actually route audio to dest separately)
      output_buffer.pushArray(scaled);
    };

    // Connect graph:
    // source -> analyser -> filter -> scriptNodeVis -> gain -> destination
    sourceNode.connect(analyser);
    analyser.connect(filterNode);
    filterNode.connect(scriptNodeVis);
    scriptNodeVis.connect(gainNode);
    gainNode.connect(audioCtx.destination);

    // Also keep a tap before filter if needed (not necessary)

    // Initialize spec_buffer to zeros
    for(let i=0;i<spec_buffer.length;i++) spec_buffer[i] = 0;

    console.log("Audio started. sampleRate:", actualSampleRate);
  } catch (err){
    console.error("Audio error:", err);
    document.getElementById('info').textContent = 'Fehler beim Zugriff auf Mikrofon: ' + err.message;
  }
}

/* -----------------------
   User Interaction / Canvas Events
   ----------------------- */
function resizeCanvas(){
  canvas.width = WINDOW_WIDTH;
  canvas.height = WINDOW_HEIGHT;
  update_layout();
}
function setCanvasSizeFromWindow(){
  const dpr = window.devicePixelRatio || 1;
  canvas.style.width = WINDOW_WIDTH + 'px';
  canvas.style.height = WINDOW_HEIGHT + 'px';
  canvas.width = WINDOW_WIDTH * dpr;
  canvas.height = WINDOW_HEIGHT * dpr;
  ctx.setTransform(dpr,0,0,dpr,0,0);
}
setCanvasSizeFromWindow();

window.addEventListener('resize', ()=> {
  // keep user's requested size when window resized? We'll adapt to browser window smaller/larger.
  // For parity with original, we allow manual resize via window size change
  WINDOW_WIDTH = Math.max(320, Math.floor(window.innerWidth * 0.6));
  WINDOW_HEIGHT = Math.max(480, Math.floor(window.innerHeight * 0.8));
  setCanvasSizeFromWindow();
  // recompute lines
  line_left = Math.floor(WINDOW_WIDTH / 4);
  line_right = Math.floor(WINDOW_WIDTH * 3 / 4);
  line_middle = Math.floor((line_left + line_right) / 2);
  spec_buffer = new Float32Array(SPEC_HISTORY * WIDTH);
});

let isMouseDown = false;
canvas.addEventListener('mousedown', (ev)=>{
  const rect = canvas.getBoundingClientRect();
  const x = ev.clientX - rect.left;
  const y = ev.clientY - rect.top;
  isMouseDown = true;
  if(pointInRect(x,y, slider_rect)){
    dragging_slider = true;
  } else {
    // check lines (vertical area from SPEC_TOP to WINDOW_HEIGHT)
    if(y >= SPEC_TOP && y <= WINDOW_HEIGHT){
      if(Math.abs(x - line_left) < 12) dragging_line = 'left';
      else if(Math.abs(x - line_right) < 12) dragging_line = 'right';
      else if(Math.abs(x - line_middle) < 12) dragging_line = 'middle';
    }
  }
});
window.addEventListener('mouseup', (ev)=>{
  dragging_slider = false;
  dragging_line = null;
  isMouseDown = false;
});
canvas.addEventListener('mousemove', (ev)=>{
  const rect = canvas.getBoundingClientRect();
  const x = ev.clientX - rect.left;
  const y = ev.clientY - rect.top;
  const dx = (ev.movementX || 0);
  if(dragging_slider){
    slider_pos = clamp(x, slider_rect.x, slider_rect.x + slider_rect.width);
    if(slider_pos <= slider_rect.x + slider_rect.width/2){
      brightness = (slider_pos - slider_rect.x) / (slider_rect.width/2);
      brightness = clamp01(brightness);
    } else {
      contrast = (slider_pos - (slider_rect.x + slider_rect.width/2)) / (slider_rect.width/2);
      contrast = clamp01(contrast);
    }
  } else if(dragging_line){
    if(dragging_line === 'left'){
      line_left = Math.max(0, Math.min(Math.floor(line_left + dx), line_right - 10));
    } else if(dragging_line === 'right'){
      line_right = Math.min(WINDOW_WIDTH, Math.max(Math.floor(line_right + dx), line_left + 10));
    } else if(dragging_line === 'middle'){
      const newLeft = line_left + dx;
      const newRight = line_right + dx;
      if(0 <= newLeft && newRight <= WINDOW_WIDTH){
        line_left = Math.floor(newLeft);
        line_right = Math.floor(newRight);
        line_middle = Math.floor((line_left + line_right) / 2);
      }
    }
    if(dragging_line !== 'middle'){
      line_middle = Math.floor((line_left + line_right) / 2);
    }
  }
});

/* -----------------------
   Utility
   ----------------------- */
function clamp(v,a,b){ return Math.max(a, Math.min(b, v)); }
function clamp01(v){ return Math.max(0, Math.min(1, v)); }
function pointInRect(x,y,rect){ return x >= rect.x && x <= rect.x+rect.width && y >= rect.y && y <= rect.y+rect.height; }

/* -----------------------
   Spectrogram helpers
   ----------------------- */
function pushSpecRow(row){
  // row: Float32Array length WIDTH (normalized 0..1)
  // shift up (drop oldest)
  // spec_buffer is row-major: [r0..rSPEC_HISTORY-1] each WIDTH long
  // move everything one row up:
  // Instead of memmove we copy
  const total = SPEC_HISTORY * WIDTH;
  // shift: move rows 1..end to 0..end-1
  for(let r=0;r<SPEC_HISTORY-1;r++){
    const src = (r+1)*WIDTH;
    const dst = r*WIDTH;
    spec_buffer.copyWithin(dst, src, src + WIDTH);
  }
  // write last row
  const last = (SPEC_HISTORY-1) * WIDTH;
  for(let i=0;i<WIDTH;i++) spec_buffer[last + i] = row[i];
}

/* -----------------------
   Main Processing Loop
   ----------------------- */
let lastTime = performance.now();
let fpsAccumulator = 0;

function render(){
  // update filter parameters from lines
  const nyq = actualSampleRate / 2;
  const f_low = (line_left / WINDOW_WIDTH) * nyq;
  const f_high = (line_right / WINDOW_WIDTH) * nyq;
  const center = Math.max(20, (f_low + f_high) / 2);
  const bw = Math.max(20, Math.abs(f_high - f_low));
  const Q = center / bw;
  if(filterNode){
    filterNode.frequency.value = center;
    filterNode.Q.value = clamp(Q, 0.1, 30);
  }

  // --- Spectrogram berechnen (ungefiltert via analyser) ---
  if(analyser){
    const freqData = new Float32Array(analyser.frequencyBinCount);
    analyser.getFloatFrequencyData(freqData); // in dB negative values usually
    // convert to magnitude-like 0..1
    // freqData min around -100..0. We'll map -100 -> 0, 0 -> 1
    const minDB = analyser.minDecibels || -100;
    const maxDB = analyser.maxDecibels || -30;
    // compute linear 0..1
    const mag = new Float32Array(freqData.length);
    for(let i=0;i<freqData.length;i++){
      mag[i] = (freqData[i] - minDB) / (maxDB - minDB);
      mag[i] = clamp01(mag[i]);
    }
    // resize/interpolate to WIDTH
    const mapped = new Float32Array(WIDTH);
    for(let x=0;x<WIDTH;x++){
      const t = x / (WIDTH - 1);
      const idx = t * (mag.length - 1);
      const i0 = Math.floor(idx);
      const i1 = Math.min(mag.length-1, i0+1);
      const frac = idx - i0;
      mapped[x] = mag[i0] * (1-frac) + mag[i1] * frac;
    }
    pushSpecRow(mapped);
  }

  // --- Audio Verarbeitung für Bandpass -> output_buffer already collected in scriptNodeVis ---
  // In addition apply contrast/gain before sending to output (gainNode already applied to destination)
  if(gainNode){
    // We'll map contrast to gainNode.gain
    gainNode.gain.value = 1 + contrast * 2;
  }

  // -----------------------
  // Rendering
  // -----------------------
  // Clear
  ctx.fillStyle = 'black';
  ctx.fillRect(0,0,WINDOW_WIDTH,WINDOW_HEIGHT);

  // TV-Bild (Bandpass gleiche Frequenzen wie Audio)
  if(frame_buffer.available() >= WIDTH * HEIGHT){
    // get last WIDTH*HEIGHT samples (without popping)
    const frame_samples = frame_buffer.peekLast(WIDTH * HEIGHT);
    // shape into HEIGHT x WIDTH
    // apply brightness (and a mild gamma like original **0.6)
    const img = ctx.createImageData(WIDTH, HEIGHT);
    for(let r=0;r<HEIGHT;r++){
      for(let c=0;c<WIDTH;c++){
        const idx = r*WIDTH + c;
        // note: original used abs(bandpassed) ** 0.6 * brightness * 255
        const v = Math.pow(Math.abs(frame_samples[idx]) || 0, 0.6) * brightness * 255;
        const vv = Math.max(0, Math.min(255, Math.floor(v)));
        const p = (r*WIDTH + c) * 4;
        img.data[p+0] = vv;
        img.data[p+1] = vv;
        img.data[p+2] = vv;
        img.data[p+3] = 255;
      }
    }
    // draw small image then scale to TV_HEIGHT x WINDOW_WIDTH
    // create temporary canvas to scale
    const tmp = document.createElement('canvas');
    tmp.width = WIDTH; tmp.height = HEIGHT;
    const tctx = tmp.getContext('2d');
    tctx.putImageData(img, 0, 0);
    ctx.drawImage(tmp, 0, 0, WINDOW_WIDTH, TV_HEIGHT);
  } else {
    // empty TV area
    ctx.fillStyle = 'black';
    ctx.fillRect(0,0,WINDOW_WIDTH, TV_HEIGHT);
  }

  // Spektrogramm
  // Create image from spec_buffer (SPEC_HISTORY x WIDTH)
  const specCanvas = document.createElement('canvas');
  specCanvas.width = WIDTH;
  specCanvas.height = SPEC_HISTORY;
  const sctx = specCanvas.getContext('2d');
  const specImg = sctx.createImageData(WIDTH, SPEC_HISTORY);
  // spec_buffer row-major rows 0..SPEC_HISTORY-1 (older..newest)
  for(let r=0;r<SPEC_HISTORY;r++){
    for(let c=0;c<WIDTH;c++){
      const v = spec_buffer[r*WIDTH + c] || 0; // 0..1
      const vv = Math.max(0, Math.min(255, Math.floor(v * 255)));
      const p = (r*WIDTH + c)*4;
      specImg.data[p+0] = vv;
      specImg.data[p+1] = vv;
      specImg.data[p+2] = vv;
      specImg.data[p+3] = 255;
    }
  }
  sctx.putImageData(specImg, 0, 0);
  // scale to full width and SPEC_HEIGHT
  ctx.drawImage(specCanvas, 0, SPEC_TOP, WINDOW_WIDTH, SPEC_HEIGHT);

  // Linien (vertical lines from SPEC_TOP..WINDOW_HEIGHT)
  ctx.strokeStyle = 'white';
  ctx.lineWidth = 2;
  ctx.beginPath();
  ctx.moveTo(line_left, SPEC_TOP);
  ctx.lineTo(line_left, WINDOW_HEIGHT);
  ctx.moveTo(line_middle, SPEC_TOP);
  ctx.lineTo(line_middle, WINDOW_HEIGHT);
  ctx.moveTo(line_right, SPEC_TOP);
  ctx.lineTo(line_right, WINDOW_HEIGHT);
  ctx.stroke();

  // Slider
  ctx.fillStyle = 'rgb(100,100,100)';
  ctx.fillRect(slider_rect.x, slider_rect.y, slider_rect.width, slider_rect.height);
  ctx.fillStyle = 'white';
  const handleX = slider_pos - 5;
  ctx.fillRect(handleX, slider_rect.y, 10, slider_rect.height);

  // Hz Skala under TV
  ctx.fillStyle = 'white';
  ctx.font = '12px Arial';
  ctx.textBaseline = 'top';
  const nyq = actualSampleRate / 2;
  for(let i=0;i<=10;i++){
    const x = Math.round((i/10) * WINDOW_WIDTH);
    const hz = Math.round((i/10) * nyq);
    const label = (hz >= 1000) ? (Math.round(hz/1000) + 'k') : (hz + ''); // keep similar to original which showed //1000k
    ctx.fillText(label, x - 10, TV_HEIGHT + 2);
    ctx.strokeStyle = 'rgb(150,150,150)';
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(x, TV_HEIGHT + 15);
    ctx.lineTo(x, SPEC_TOP);
    ctx.stroke();
  }

  // small info text
  ctx.fillStyle = '#ddd';
  ctx.font = '12px Arial';
  ctx.fillText('brightness: ' + brightness.toFixed(2) + ' contrast: ' + contrast.toFixed(2), 10, WINDOW_HEIGHT - 50);

  requestAnimationFrame(render);
}

/* -----------------------
   Start
   ----------------------- */
startAudio().then(()=> {
  requestAnimationFrame(render);
});

/* -----------------------
   Graceful stop on page unload
   ----------------------- */
window.addEventListener('beforeunload', ()=>{
  try{
    if(micStream){
      const tracks = micStream.getTracks();
      tracks.forEach(t=>t.stop());
    }
    if(audioCtx) audioCtx.close();
  } catch(e){}
});

</script>
</body>
</html>
